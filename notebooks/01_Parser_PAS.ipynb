{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMj0kzcIxcXbOEJzjNXK7N/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Projeto PAS - Notebook 01: Parser de PDF e Limpeza de Dados\n","\n","**Objetivo:** Este *notebook* executa o *pipeline* de extração, transformação e carga (ETL). Sua responsabilidade é processar múltiplos arquivos PDF de resultados do Cebraspe (um para cada triênio) e salvá-los como um único `DataFrame` mestre, limpo e padronizado.\n","\n","**Input:** Múltiplos arquivos `.pdf` (ex: `PAS_2022_2024.pdf`)\n","\n","**Output:** Um único `DataFrame` mestre: `PAS_MESTRE_LIMPO_FINAL.csv`"],"metadata":{"id":"4UV2kJjK30Sf"}},{"cell_type":"code","source":["!pip install pdfplumber"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h3m0x1TSEyNa","executionInfo":{"status":"ok","timestamp":1762134918923,"user_tz":180,"elapsed":9248,"user":{"displayName":"Luiz Moreira","userId":"17999712471707324317"}},"outputId":"3b4f4062-c17c-467d-e9e1-51086617484c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pdfplumber\n","  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pdfminer.six==20250506 (from pdfplumber)\n","  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n","Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n","Collecting pypdfium2>=4.18.0 (from pdfplumber)\n","  Downloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.4)\n","Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n","Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pypdfium2-5.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n","Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-5.0.0\n"]}]},{"cell_type":"markdown","source":["### Tarefa 1: Setup - Conectando ao Google Drive\n","Como os arquivos PDF de origem estão armazenados no Google Drive, o primeiro passo é montar (conectar) o *notebook* ao sistema de arquivos do Drive."],"metadata":{"id":"-ko6OlOGhaZv"}},{"cell_type":"code","source":["import pdfplumber\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUuPam573rDN","executionInfo":{"status":"ok","timestamp":1762134940334,"user_tz":180,"elapsed":19560,"user":{"displayName":"Luiz Moreira","userId":"17999712471707324317"}},"outputId":"e3633c0e-f513-4a0d-94f0-964eb958e03f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["### Tarefa 2: A Ferramenta (A Função \"Parser\")\n","\n","Esta é a função principal de limpeza, `parse_pas_pdf`. Ela foi projetada para ser robusta e lidar com as inconsistências de formato encontradas ao longo dos 7 anos de relatórios em PDF.\n","\n","Ela implementa 4 lógicas de engenharia de dados para tratar problemas complexos identificados durante a prototipagem:\n","\n","1.  **Tratamento de \"Linha Quebrada\":** Os dados de um único aluno podem ser quebrados em múltiplas linhas no PDF.\n","    * **Solução:** O *parser* primeiro junta (`.join()`) todo o texto da página em uma \"MegaString\" para garantir a integridade dos dados antes do processamento.\n","2.  **Identificação do \"Separador\":** O delimitador de aluno real não é uma linha nova (`\\n`), mas sim o caractere ` / `.\n","    * **Solução:** A \"MegaString\" é dividida (`.split(' / ')`) usando este delimitador.\n","3.  **Detecção de \"Âncora\" (Robusta):** Os cabeçalhos dos PDFs têm tamanhos inconsistentes (de 31 a 7097 linhas).\n","    * **Solução:** O *parser* \"caça\" por âncoras de texto (como \"ADMINISTRAÇÃO (BACHARELADO)\" ou \"1.1.1.1\") para encontrar dinamicamente o início dos dados reais.\n","4.  **Tratamento de Dados \"Irregulares\":** Alunos têm um número variável de colunas.\n","    * **Solução:** O *parser* implementa \"acolchoamento\" (padding), detectando o comprimento máximo (`max_cols`) e preenchendo linhas mais curtas com `None` para criar um `DataFrame` retangular.\n","\n","A função também aplica a limpeza final (conversão de tipo para `float` com `pd.to_numeric` e remoção de alunos eliminados com `.dropna()`)."],"metadata":{"id":"5R1wLyFx5FuV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKo3z0gL3WZh"},"outputs":[],"source":["import pdfplumber\n","import pandas as pd\n","import re\n","import numpy as np\n","\n","def parse_pas_pdf(caminho_pdf, ano_trienio):\n","    print(f\"\\n--- Processando Triênio: {ano_trienio} ---\")\n","    print(f\"Lendo arquivo: {caminho_pdf}\")\n","\n","    todas_as_linhas = []\n","    try:\n","        with pdfplumber.open(caminho_pdf) as pdf:\n","            for pagina in pdf.pages:\n","                texto_da_pagina = pagina.extract_text()\n","                if texto_da_pagina:\n","                    linhas_da_pagina = texto_da_pagina.split('\\n')\n","                    todas_as_linhas.extend(linhas_da_pagina)\n","    except Exception as e:\n","        print(f\"!!! ERRO AO LER O PDF: {e}\")\n","        return None\n","\n","    indice_de_inicio = -1\n","\n","    for i, linha in enumerate(todas_as_linhas):\n","        linha_upper = linha.upper()\n","\n","        if \"1.1.1.1\" in linha and \"ADMINISTRAÇÃO\" in linha_upper:\n","            print(f\"Encontrada 'âncora' (Padrão 2018) na linha {i}.\")\n","            indice_de_inicio = i\n","            break\n","\n","        elif \"ADMINISTRAÇÃO (BACHARELADO)\" == linha_upper:\n","            print(f\"Encontrada 'âncora' (Padrão 2024) na linha {i}.\")\n","            indice_de_inicio = i\n","            break\n","\n","    if indice_de_inicio == -1:\n","        print(f\"!!! ERRO: Não foi possível achar a 'âncora' (ADMINISTRAÇÃO ou 1.1.1.1) no PDF de {ano_trienio}.\")\n","        return None\n","\n","    linhas_de_dados = todas_as_linhas[indice_de_inicio:]\n","    megastring = \" \".join(linhas_de_dados)\n","    lista_de_alunos_sujos = megastring.split(' / ')\n","\n","    padrao_aluno = re.compile(r\"^(\\d{8}), ([\\w\\s'-]+), ([\\d\\., -]+.*)\")\n","    padrao_split_notas = re.compile(r\", ?\")\n","\n","    dados_limpos_listas = []\n","    for aluno_str in lista_de_alunos_sujos:\n","        aluno_str_limpo = aluno_str.strip()\n","        match = re.search(padrao_aluno, aluno_str_limpo)\n","\n","        if match:\n","            inscricao = match.group(1); nome = match.group(2).strip()\n","            notas_str = match.group(3); notas_lista = re.split(padrao_split_notas, notas_str)\n","            linha_final = [inscricao, nome] + notas_lista\n","            dados_limpos_listas.append(linha_final)\n","\n","    if not dados_limpos_listas:\n","        print(f\"Nenhum aluno encontrado com o padrão Regex. O formato do PDF de {ano_trienio} pode ser diferente.\")\n","        return None\n","\n","    max_cols = 0\n","    for linha in dados_limpos_listas: max_cols = max(max_cols, len(linha))\n","\n","    if max_cols < 12:\n","        print(f\"!!! ERRO: O parser encontrou dados, mas as colunas parecem erradas (max_cols = {max_cols}).\")\n","        return None\n","\n","    dados_preenchidos = []\n","    for linha in dados_limpos_listas:\n","        colunas_faltando = max_cols - len(linha)\n","        linha_preenchida = linha + ([None] * colunas_faltando)\n","        dados_preenchidos.append(linha_preenchida)\n","\n","    colunas_nomes = ['Inscricao', 'Nome', 'P1_PAS1', 'P2_PAS1', 'Red_PAS1', 'P1_PAS2', 'P2_PAS2', 'Red_PAS2', 'P1_PAS3', 'P2_PAS3', 'Red_PAS3', 'Arg_Final']\n","    colunas_lixo = [f'Class_{i+1}' for i in range(max_cols - len(colunas_nomes))]\n","    colunas_final = colunas_nomes + colunas_lixo\n","\n","    df = pd.DataFrame(dados_preenchidos, columns=colunas_final)\n","\n","    df_fatiado = df[colunas_nomes].copy()\n","\n","    colunas_para_converter = [\n","        'P1_PAS1', 'P2_PAS1', 'Red_PAS1', 'P1_PAS2', 'P2_PAS2', 'Red_PAS2',\n","        'P1_PAS3', 'P2_PAS3', 'Red_PAS3', 'Arg_Final'\n","    ]\n","    for coluna in colunas_para_converter:\n","        df_fatiado.loc[:, coluna] = pd.to_numeric(df_fatiado[coluna], errors='coerce')\n","\n","    df_limpo = df_fatiado.dropna(subset=colunas_para_converter).copy()\n","\n","    df_limpo.loc[:, 'Ano_Trienio'] = ano_trienio\n","\n","    print(f\"Limpeza concluída. Encontramos {len(df_limpo)} alunos 'sobreviventes'.\")\n","\n","    return df_limpo\n"]},{"cell_type":"markdown","source":["### Tarefa 3: Processamento em Lote\n","\n","Esta célula executa o *pipeline* de limpeza.\n","\n","Ela utiliza a função `parse_pas_pdf` (definida acima) e a aplica iterativamente a um dicionário (`arquivos_para_processar`) que mapeia cada triênio ao seu respectivo nome de arquivo PDF.\n","\n","Cada *dataset* de ano limpo é salvo individualmente como um `.csv` (ex: `PAS_2022-2024_LIMPO.csv`)."],"metadata":{"id":"XMMx5GfOiKox"}},{"cell_type":"code","source":["lista_de_dataframes = []\n","\n","base_path = '/content/drive/MyDrive/Projeto PAS/'\n","\n","arquivos_para_processar = {\n","    '2022-2024': 'Ed_38_2024_PAS_3_2022-2024_Res_final_não_eliminados.pdf',\n","    '2021-2023': 'Ed_27_PAS_3_2021_2023_Res_final_tipo_D_redação.pdf',\n","    '2020-2022': 'Ed_30_PAS_3_2020_2022_Res_Final_Tipo D_Redação.pdf',\n","    '2019-2021': 'Ed_30_PAS_3_2019_2021_Res_Final_Tipo D_Redação.pdf',\n","    '2018-2020': 'ED_37_PAS_3 _2018 -2020_Final_Tipo_D_Redacao.pdf',\n","    '2017-2019': 'Ed_36_PAS_3 _2017 -2019_Res_final_tipo_D_redacao_rel_nao_elimin.pdf',\n","    '2016-2018': 'Ed_31_2016-2018_PAS_3_Res_final_nao_eliminados.pdf'\n","}\n","\n","\n","print(f\"--- Iniciando Fase 1.B: Processamento em Lote ---\")\n","\n","for ano, nome_arquivo in arquivos_para_processar.items():\n","\n","    caminho_completo = base_path + nome_arquivo\n","\n","    df_limpo_ano = parse_pas_pdf(caminho_pdf=caminho_completo, ano_trienio=ano)\n","\n","    if df_limpo_ano is not None:\n","\n","        caminho_csv = f\"{base_path}PAS_{ano}_LIMPO.csv\"\n","        df_limpo_ano.to_csv(caminho_csv, index=False)\n","        print(f\"SUCESSO! Arquivo '{caminho_csv}' salvo.\")\n","\n","        lista_de_dataframes.append(df_limpo_ano)\n","\n","if lista_de_dataframes:\n","    print(\"\\n--- Juntando todos os triênios em um DataFrame Mestre ---\")\n","\n","    df_mestre = pd.concat(lista_de_dataframes, ignore_index=True)\n","\n","    caminho_mestre_csv = f\"{base_path}PAS_MESTRE_LIMPO.csv\"\n","    df_mestre.to_csv(caminho_mestre_csv, index=False)\n","\n","    print(f\"\\n--- PROJETO (PARSER) CONCLUÍDO! ---\")\n","    print(f\"Arquivo Mestre '{caminho_mestre_csv}' salvo.\")\n","    print(f\"Total de alunos 'sobreviventes' em todos os anos: {len(df_mestre)}\")\n","    print(\"\\nAmostra do DataFrame Mestre:\")\n","    print(df_mestre.head())\n","    print(df_mestre.tail())\n","\n","else:\n","    print(\"Nenhum arquivo foi processado com sucesso.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vs2OSUUI3-_o","executionInfo":{"status":"ok","timestamp":1762113676585,"user_tz":180,"elapsed":872327,"user":{"displayName":"Luiz Moreira","userId":"17999712471707324317"}},"outputId":"9f6bed0d-1f71-4147-a920-9db6680ce9e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Iniciando Fase 1.B: Processamento em Lote ---\n","\n","--- Processando Triênio: 2022-2024 ---\n","Lendo arquivo: /content/drive/MyDrive/Projeto PAS/Ed_38_2024_PAS_3_2022-2024_Res_final_não_eliminados.pdf\n","Encontrada 'âncora' de início dos dados na linha 31.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1319857419.py:115: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_limpo['Ano_Trienio'] = ano_trienio\n"]},{"output_type":"stream","name":"stdout","text":["Limpeza concluída. Encontramos 8119 alunos 'sobreviventes'.\n","SUCESSO! Arquivo '/content/drive/MyDrive/Projeto PAS/PAS_2022-2024_LIMPO.csv' salvo.\n","\n","--- Processando Triênio: 2021-2023 ---\n","Lendo arquivo: /content/drive/MyDrive/Projeto PAS/Ed_27_PAS_3_2021_2023_Res_final_tipo_D_redação.pdf\n","Encontrada 'âncora' de início dos dados na linha 4875.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1319857419.py:115: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_limpo['Ano_Trienio'] = ano_trienio\n"]},{"output_type":"stream","name":"stdout","text":["Limpeza concluída. Encontramos 7630 alunos 'sobreviventes'.\n","SUCESSO! Arquivo '/content/drive/MyDrive/Projeto PAS/PAS_2021-2023_LIMPO.csv' salvo.\n","\n","--- Processando Triênio: 2020-2022 ---\n","Lendo arquivo: /content/drive/MyDrive/Projeto PAS/Ed_30_PAS_3_2020_2022_Res_Final_Tipo D_Redação.pdf\n","Encontrada 'âncora' de início dos dados na linha 4920.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1319857419.py:115: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_limpo['Ano_Trienio'] = ano_trienio\n"]},{"output_type":"stream","name":"stdout","text":["Limpeza concluída. Encontramos 6854 alunos 'sobreviventes'.\n","SUCESSO! Arquivo '/content/drive/MyDrive/Projeto PAS/PAS_2020-2022_LIMPO.csv' salvo.\n","\n","--- Processando Triênio: 2019-2021 ---\n","Lendo arquivo: /content/drive/MyDrive/Projeto PAS/Ed_30_PAS_3_2019_2021_Res_Final_Tipo D_Redação.pdf\n","Encontrada 'âncora' de início dos dados na linha 5644.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1319857419.py:115: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_limpo['Ano_Trienio'] = ano_trienio\n"]},{"output_type":"stream","name":"stdout","text":["Limpeza concluída. Encontramos 8105 alunos 'sobreviventes'.\n","SUCESSO! Arquivo '/content/drive/MyDrive/Projeto PAS/PAS_2019-2021_LIMPO.csv' salvo.\n","\n","--- Processando Triênio: 2018-2020 ---\n","Lendo arquivo: /content/drive/MyDrive/Projeto PAS/ED_37_PAS_3 _2018 -2020_Final_Tipo_D_Redacao.pdf\n","Encontrada 'âncora' de início dos dados na linha 3772.\n","Limpeza concluída. Encontramos 5556 alunos 'sobreviventes'.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1319857419.py:115: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_limpo['Ano_Trienio'] = ano_trienio\n"]},{"output_type":"stream","name":"stdout","text":["SUCESSO! Arquivo '/content/drive/MyDrive/Projeto PAS/PAS_2018-2020_LIMPO.csv' salvo.\n","\n","--- Processando Triênio: 2017-2019 ---\n","Lendo arquivo: /content/drive/MyDrive/Projeto PAS/Ed_36_PAS_3 _2017 -2019_Res_final_tipo_D_redacao_rel_nao_elimin.pdf\n","Encontrada 'âncora' de início dos dados na linha 7097.\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1319857419.py:115: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df_limpo['Ano_Trienio'] = ano_trienio\n"]},{"output_type":"stream","name":"stdout","text":["Limpeza concluída. Encontramos 9300 alunos 'sobreviventes'.\n","SUCESSO! Arquivo '/content/drive/MyDrive/Projeto PAS/PAS_2017-2019_LIMPO.csv' salvo.\n","\n","--- Processando Triênio: 2016-2018 ---\n","Lendo arquivo: /content/drive/MyDrive/Projeto PAS/Ed_31_2016-2018_PAS_3_Res_final_nao_eliminados.pdf\n","!!! ERRO: Não foi possívelADMINISTRAÇÃO (BACHARELADO) achar a 'âncora' (ex: ADMINISTRAÇÃO) no PDF de 2016-2018.\n","    O parser pode precisar de uma nova 'âncora' para este ano.\n","\n","--- Juntando todos os triênios em um DataFrame Mestre ---\n","\n","--- PROJETO (PARSER) CONCLUÍDO! ---\n","Arquivo Mestre '/content/drive/MyDrive/Projeto PAS/PAS_MESTRE_LIMPO.csv' salvo.\n","Total de alunos 'sobreviventes' em todos os anos: 45564\n","\n","Amostra do DataFrame Mestre:\n","  Inscricao                                  Nome P1_PAS1 P2_PAS1 Red_PAS1  \\\n","0  22103536              Admilson Vieira de Moura   4.385  13.447    5.567   \n","1  22121163          Alex Vitor Goncalves Barbosa   1.169   9.061    5.799   \n","2  22125011              Alexandre Lobo Parreiras   1.754  14.616    6.074   \n","3  22109511  Alexandre Nascimento Ferreira Santos   2.046   7.308    5.315   \n","4  22103988   Amanda Fernandes de Caldas da Silva   9.647  39.793    8.391   \n","\n","  P1_PAS2 P2_PAS2 Red_PAS2 P1_PAS3 P2_PAS3 Red_PAS3 Arg_Final Ano_Trienio  \n","0   6.152  19.224    6.267   3.141  16.916    9.407   -38.435   2022-2024  \n","1   4.614  27.325    6.515   3.141  31.899    5.111   -13.476   2022-2024  \n","2   3.076  10.253     7.63   0.966  24.166    7.929   -44.567   2022-2024  \n","3   4.614   14.61    6.683   2.175  10.632    5.333   -70.891   2022-2024  \n","4    7.69  47.525    9.867   7.975  54.616     10.0    89.957   2022-2024  \n","      Inscricao                               Nome P1_PAS1 P2_PAS1 Red_PAS1  \\\n","45559  17105949     Joao Pedro Lima de Sa Bandeira    2.52  33.319    5.206   \n","45560  17109262            Larissa Lazaro Roncador    5.88  31.359    4.934   \n","45561  17198847              Mateus Santana Campos     0.0  20.719      0.0   \n","45562  17175394            Roberta Rocha Anastacio    3.36  36.399      8.4   \n","45563  17196260  Vitoria Cristhina da Silva Santos    7.56  31.918    7.714   \n","\n","      P1_PAS2 P2_PAS2 Red_PAS2 P1_PAS3 P2_PAS3 Red_PAS3 Arg_Final Ano_Trienio  \n","45559   1.588   26.73    4.538   3.893  16.303    4.667   -18.263   2017-2019  \n","45560   8.734  35.729    5.664    3.65  31.633    7.083    35.524   2017-2019  \n","45561   0.794  17.732    4.214    1.46   21.17      5.1   -32.889   2017-2019  \n","45562  -0.794  24.083    5.917    2.19  23.603    7.307     2.148   2017-2019  \n","45563   6.616  35.464    6.885    2.19   13.87    6.472    -3.539   2017-2019  \n"]}]},{"cell_type":"markdown","source":["### Tarefa 4: Resgate de Dados (Debug de 2016-2018)\n","\n","O *parser* V2.3 falhou no PDF de 2018, pois a \"âncora\" de texto era diferente (`1.1.1.1 ADMINISTRAÇÃO...`). Esta célula foi usada para \"resgatar\" cirurgicamente apenas aquele arquivo, aplicando a lógica de *parser* V2.4 (definida na Célula 2), sem a necessidade de re-processar os 6 arquivos que já haviam sido concluídos."],"metadata":{"id":"jD-3McvoiV2B"}},{"cell_type":"code","source":["base_path = '/content/drive/MyDrive/Projeto PAS/'\n","\n","ano_falho = '2016-2018'\n","arquivo_falho = 'Ed_31_2016-2018_PAS_3_Res_final_nao_eliminados.pdf'\n","\n","caminho_completo = base_path + arquivo_falho\n","\n","df_resgatado = parse_pas_pdf(caminho_pdf=caminho_completo, ano_trienio=ano_falho)\n","\n","if df_resgatado is not None:\n","    caminho_csv = f\"{base_path}PAS_{ano_falho}_LIMPO.csv\"\n","    df_resgatado.to_csv(caminho_csv, index=False)\n","    print(f\"SUCESSO! Arquivo '{caminho_csv}' salvo.\")\n","else:\n","    print(f\"--- FALHA NO RESGATE. O parser V2.3 ainda não é bom o suficiente. ---\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XB_bTM7WbckE","executionInfo":{"status":"ok","timestamp":1762135369695,"user_tz":180,"elapsed":67562,"user":{"displayName":"Luiz Moreira","userId":"17999712471707324317"}},"outputId":"9cd96322-b298-45e9-8539-451c1d970287"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Processando Triênio: 2016-2018 ---\n","Lendo arquivo: /content/drive/MyDrive/Projeto PAS/Ed_31_2016-2018_PAS_3_Res_final_nao_eliminados.pdf\n","Encontrada 'âncora' (Padrão 2018) na linha 35.\n","Limpeza concluída. Encontramos 3194 alunos 'sobreviventes'.\n","SUCESSO! Arquivo '/content/drive/MyDrive/Projeto PAS/PAS_2016-2018_LIMPO.csv' salvo.\n"]}]},{"cell_type":"markdown","source":["### Tarefa 5: Consolidação Final (O \"DataFrame Mestre\")\n","\n","Este é o passo final do *pipeline* de engenharia.\n","\n","**Desafio de Consolidação:** O método de consolidação precisa ser \"idempotente\" (seguro para rodar múltiplas vezes). Uma busca genérica (`glob`) pelos arquivos `.csv` criados pode acidentalmente incluir os próprios arquivos \"Mestre\" de saídas anteriores, criando duplicatas.\n","\n","**Solução:**\n","1.  **Limpeza de Artefatos:** Arquivos `_MESTRE_` de saídas anteriores são removidos do diretório.\n","2.  **\"Caçador Inteligente\" (Glob):** O padrão `glob` é refinado para `PAS_????-????_LIMPO.csv`. Este padrão é específico e \"caça\" *apenas* os 7 arquivos de triênio, ignorando qualquer outro arquivo.\n","3.  **Resultado:** `pd.concat()` é usado para \"empilhar\" os 7 CSVs limpos em um `DataFrame` mestre final (`PAS_MESTRE_LIMPO_FINAL.csv`), contendo **48.758 alunos**."],"metadata":{"id":"EX4eSsLHipMg"}},{"cell_type":"code","source":["base_path = '/content/drive/MyDrive/Projeto PAS/'\n","\n","ano_regenerar = '2022-2024'\n","arquivo_regenerar = 'Ed_38_2024_PAS_3_2022-2024_Res_final_nao_eliminados.pdf'\n","\n","caminho_completo = base_path + arquivo_regenerar\n","\n","df_regenerado = parse_pas_pdf(caminho_pdf=caminho_completo, ano_trienio=ano_regenerar)\n","\n","if df_regenerado is not None:\n","    caminho_csv = f\"{base_path}PAS_{ano_regenerar}_LIMPO.csv\"\n","    df_regenerado.to_csv(caminho_csv, index=False)\n","    print(f\"SUCESSO! Arquivo '{caminho_csv}' (V2.4) salvo.\")\n","else:\n","    print(f\"--- FALHA NA REGENERAÇÃO. O parser V2.4 falhou no 2024. ---\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ld8VEUeftmP","executionInfo":{"status":"ok","timestamp":1762136246459,"user_tz":180,"elapsed":128629,"user":{"displayName":"Luiz Moreira","userId":"17999712471707324317"}},"outputId":"224e9119-a052-4097-8a56-742ba62dcc6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- Processando Triênio: 2022-2024 ---\n","Lendo arquivo: /content/drive/MyDrive/Projeto PAS/Ed_38_2024_PAS_3_2022-2024_Res_final_não_eliminados.pdf\n","Encontrada 'âncora' (Padrão 2024) na linha 31.\n","Limpeza concluída. Encontramos 8119 alunos 'sobreviventes'.\n","SUCESSO! Arquivo '/content/drive/MyDrive/Projeto PAS/PAS_2022-2024_LIMPO.csv' (V2.4) salvo.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import glob\n","\n","base_path = '/content/drive/MyDrive/Projeto PAS/'\n","\n","padrao_de_busca = base_path + 'PAS_????-????_LIMPO.csv'\n","\n","arquivos_csv_limpos = glob.glob(padrao_de_busca)\n","\n","if not arquivos_csv_limpos:\n","    print(\"ERRO: Nenhum arquivo .csv limpo foi encontrado.\")\n","else:\n","    print(f\"Encontrados {len(arquivos_csv_limpos)} arquivos CSV de triênios para juntar:\")\n","    print(sorted(arquivos_csv_limpos))\n","\n","    lista_de_dataframes = []\n","\n","    for arquivo_csv in arquivos_csv_limpos:\n","        df_ano = pd.read_csv(arquivo_csv)\n","        lista_de_dataframes.append(df_ano)\n","\n","    df_mestre = pd.concat(lista_de_dataframes, ignore_index=True)\n","\n","    caminho_mestre_csv = f\"{base_path}PAS_MESTRE_LIMPO_FINAL.csv\"\n","    df_mestre.to_csv(caminho_mestre_csv, index=False)\n","\n","    print(\"\\n--- PROJETO (PARSER) CONCLUÍDO! ---\")\n","    print(f\"Arquivo Mestre '{caminho_mestre_csv}' salvo.\")\n","\n","    print(\"\\n--- Informações do DataFrame Mestre ---\")\n","    df_mestre.info()\n","\n","    print(\"\\n--- Composição do DataFrame Mestre (Contagem por Ano) ---\")\n","    print(df_mestre['Ano_Trienio'].value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qIxxxGhPdvf4","executionInfo":{"status":"ok","timestamp":1762136300599,"user_tz":180,"elapsed":919,"user":{"displayName":"Luiz Moreira","userId":"17999712471707324317"}},"outputId":"2489d95c-35ef-4544-c664-9f0b45bd69b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Iniciando Tarefa 19.B: Consolidação Final (Pós-Limpeza) ---\n","Encontrados 7 arquivos CSV de triênios para juntar:\n","['/content/drive/MyDrive/Projeto PAS/PAS_2016-2018_LIMPO.csv', '/content/drive/MyDrive/Projeto PAS/PAS_2017-2019_LIMPO.csv', '/content/drive/MyDrive/Projeto PAS/PAS_2018-2020_LIMPO.csv', '/content/drive/MyDrive/Projeto PAS/PAS_2019-2021_LIMPO.csv', '/content/drive/MyDrive/Projeto PAS/PAS_2020-2022_LIMPO.csv', '/content/drive/MyDrive/Projeto PAS/PAS_2021-2023_LIMPO.csv', '/content/drive/MyDrive/Projeto PAS/PAS_2022-2024_LIMPO.csv']\n","\n","--- PROJETO (PARSER) CONCLUÍDO! ---\n","Arquivo Mestre '/content/drive/MyDrive/Projeto PAS/PAS_MESTRE_LIMPO_FINAL.csv' salvo.\n","\n","--- Informações do DataFrame Mestre ---\n","<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 48758 entries, 0 to 48757\n","Data columns (total 13 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   Inscricao    48758 non-null  int64  \n"," 1   Nome         48758 non-null  object \n"," 2   P1_PAS1      48758 non-null  float64\n"," 3   P2_PAS1      48758 non-null  float64\n"," 4   Red_PAS1     48758 non-null  float64\n"," 5   P1_PAS2      48758 non-null  float64\n"," 6   P2_PAS2      48758 non-null  float64\n"," 7   Red_PAS2     48758 non-null  float64\n"," 8   P1_PAS3      48758 non-null  float64\n"," 9   P2_PAS3      48758 non-null  float64\n"," 10  Red_PAS3     48758 non-null  float64\n"," 11  Arg_Final    48758 non-null  float64\n"," 12  Ano_Trienio  48758 non-null  object \n","dtypes: float64(10), int64(1), object(2)\n","memory usage: 4.8+ MB\n","\n","--- Composição do DataFrame Mestre (Contagem por Ano) ---\n","Ano_Trienio\n","2017-2019    9300\n","2022-2024    8119\n","2019-2021    8105\n","2021-2023    7630\n","2020-2022    6854\n","2018-2020    5556\n","2016-2018    3194\n","Name: count, dtype: int64\n"]}]}]}